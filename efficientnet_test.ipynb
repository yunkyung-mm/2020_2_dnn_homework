{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "efficientnet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NUX8CcXVHd8",
        "outputId": "f7011c24-1435-4fc3-df96-c4866de5665d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!pip install efficientnet_pytorch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: efficientnet_pytorch in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from efficientnet_pytorch) (1.6.0+cu101)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->efficientnet_pytorch) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-4MLt3kVgou"
      },
      "source": [
        "from efficientnet_pytorch import EfficientNet\n",
        "model = EfficientNet.from_name('efficientnet-b0')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mmg7xF_CV35k",
        "outputId": "28a935df-3e9d-48f0-b167-112e56615216",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import json\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torchvision import transforms\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import random\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "model_name = 'efficientnet-b0'  # b5\n",
        "\n",
        "image_size = EfficientNet.get_image_size(model_name)\n",
        "print(image_size)\n",
        "model = EfficientNet.from_name(model_name, num_classes=10)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "224\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecAS63dLWEAN",
        "outputId": "bfe305d2-b2ae-43fe-a423-f19f41595b09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "learning_rate=0.001\n",
        "batch_size  = 128\n",
        "epoch_num = 100\n",
        "random_seed = 555\n",
        "random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)\n",
        "\n",
        "## make dataset\n",
        "from torchvision import transforms, datasets\n",
        "data_path = './train/'  # class 별 폴더로 나누어진걸 확 가져와서 라벨도 달아준다\n",
        "stl10_dataset = datasets.ImageFolder(\n",
        "                                data_path,\n",
        "                                transforms.Compose([\n",
        "                                    transforms.Resize(96),\n",
        "                                    transforms.RandomCrop(96, padding=4),\n",
        "                                    transforms.RandomHorizontalFlip(),\n",
        "                                    transforms.RandomRotation(15),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
        "                                ]))\n",
        "## data split\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Subset\n",
        "train_idx, valid_idx = train_test_split(list(range(len(stl10_dataset))), test_size=0.1, random_state=random_seed)\n",
        "datasets = {}\n",
        "datasets['train'] = Subset(stl10_dataset, train_idx)\n",
        "datasets['valid'] = Subset(stl10_dataset, valid_idx)\n",
        "\n",
        "## data loader\n",
        "dataloaders, batch_num = {}, {}\n",
        "dataloaders['train'] = torch.utils.data.DataLoader(datasets['train'],\n",
        "                                              batch_size=batch_size, shuffle=True,\n",
        "                                              num_workers=4)\n",
        "dataloaders['valid'] = torch.utils.data.DataLoader(datasets['valid'],\n",
        "                                              batch_size=batch_size, shuffle=False,\n",
        "                                              num_workers=4)\n",
        "\n",
        "\n",
        "normalize = transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
        "                                  std=[0.5, 0.5, 0.5])\n",
        "test_transform = transforms.Compose([transforms.Resize(96),\n",
        "    transforms.ToTensor(),\n",
        "    normalize\n",
        "])\n",
        "\n",
        "# test_dataset = torchvision.datasets.ImageFolder('./test/', transform=test_transform)\n",
        "# test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=4, shuffle=False)\n",
        "\n",
        "testset=torchvision.datasets.STL10(root='./data', split='test')\n",
        "            \n",
        "\n",
        "batch_num['train'], batch_num['valid'] = len(dataloaders['train']), len(dataloaders['valid'])\n",
        "print('batch_size : %d,  tvt : %d / %d ' % (batch_size, batch_num['train'], batch_num['valid']))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch_size : 128,  tvt : 36 / 4 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sh3eJpu3XARY"
      },
      "source": [
        "def train_model(model, criterion, optimizer, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_loss = 10.0\n",
        "    train_loss, train_acc, valid_loss, valid_acc= [], [], [], []\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'valid']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss, running_corrects, num_cnt = 0.0, 0, 0\n",
        "            \n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "                num_cnt += len(labels)\n",
        "            \n",
        "            epoch_loss = float(running_loss / num_cnt)\n",
        "            epoch_acc  = float((running_corrects.double() / num_cnt).cpu()*100)\n",
        "            \n",
        "            if phase == 'train':\n",
        "                train_loss.append(epoch_loss)\n",
        "                train_acc.append(epoch_acc)\n",
        "            else:\n",
        "                valid_loss.append(epoch_loss)\n",
        "                valid_acc.append(epoch_acc)\n",
        "            print('{} Loss: {:.5f} Acc: {:.3f}'.format(phase, epoch_loss, epoch_acc))\n",
        "           \n",
        "    \n",
        "\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'valid' and epoch_loss < best_loss:\n",
        "                best_idx = epoch\n",
        "                best_loss = epoch_loss\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                model.load_state_dict(best_model_wts)\n",
        "                torch.save(model.state_dict(), './stl10_model_epoch_%d.pth'%(epoch))\n",
        "        \n",
        "        Category = []\n",
        "        correct=0\n",
        "        model.eval()\n",
        "        for input, _ in test_loader:\n",
        "            input = input.cuda()\n",
        "            output = model(input)\n",
        "            output = torch.argmax(output, dim=1)\n",
        "            answer = output.tolist()\n",
        "            Category = Category + output.tolist()\n",
        "\n",
        "        for i in range(8000):\n",
        "            if Category[i]==testset.__getitem__(i)[1]:\n",
        "                correct=correct+1\n",
        "        print(\"correct : %d / 8000\" %(correct))\n",
        "        print(\"accuracy : %0.3f\\n\" %(correct/8000))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best valid Acc: %d - %.5f' %(best_idx, best_loss))\n",
        "\n",
        "    return model, best_idx, best_loss, train_loss, train_acc, valid_loss, valid_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WcxUihQYBqa"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # set gpu\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer_ft=optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
        "\n",
        "lmbda = lambda epoch: 0.98739\n",
        "exp_lr_scheduler = optim.lr_scheduler.MultiplicativeLR(optimizer_ft, lr_lambda=lmbda)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nuY2lLrYHDg",
        "outputId": "37316df6-212e-406e-e695-44f180ce5608",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#training part \n",
        "\n",
        "model, best_idx, best_loss, train_loss, train_acc, valid_loss, valid_acc = train_model(model, criterion, optimizer_ft, num_epochs=epoch_num)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/99\n",
            "----------\n",
            "train Loss: 2.04589 Acc: 22.249\n",
            "valid Loss: 2.31129 Acc: 8.383\n",
            "correct : 800 / 8000\n",
            "accuracy : 0.100\n",
            "\n",
            "Epoch 1/99\n",
            "----------\n",
            "train Loss: 1.68474 Acc: 31.588\n",
            "valid Loss: 2.35614 Acc: 7.585\n",
            "correct : 800 / 8000\n",
            "accuracy : 0.100\n",
            "\n",
            "Epoch 2/99\n",
            "----------\n",
            "train Loss: 1.49659 Acc: 39.796\n",
            "valid Loss: 2.46381 Acc: 7.585\n",
            "correct : 800 / 8000\n",
            "accuracy : 0.100\n",
            "\n",
            "Epoch 3/99\n",
            "----------\n",
            "train Loss: 1.33218 Acc: 48.758\n",
            "valid Loss: 2.62818 Acc: 7.585\n",
            "correct : 800 / 8000\n",
            "accuracy : 0.100\n",
            "\n",
            "Epoch 4/99\n",
            "----------\n",
            "train Loss: 1.14959 Acc: 56.788\n",
            "valid Loss: 2.91827 Acc: 7.585\n",
            "correct : 800 / 8000\n",
            "accuracy : 0.100\n",
            "\n",
            "Epoch 5/99\n",
            "----------\n",
            "train Loss: 0.94625 Acc: 64.973\n",
            "valid Loss: 3.05963 Acc: 7.585\n",
            "correct : 800 / 8000\n",
            "accuracy : 0.100\n",
            "\n",
            "Epoch 6/99\n",
            "----------\n",
            "train Loss: 0.78001 Acc: 71.739\n",
            "valid Loss: 3.28771 Acc: 8.383\n",
            "correct : 800 / 8000\n",
            "accuracy : 0.100\n",
            "\n",
            "Epoch 7/99\n",
            "----------\n",
            "train Loss: 0.63137 Acc: 77.507\n",
            "valid Loss: 3.96746 Acc: 7.585\n",
            "correct : 800 / 8000\n",
            "accuracy : 0.100\n",
            "\n",
            "Epoch 8/99\n",
            "----------\n",
            "train Loss: 0.51129 Acc: 82.343\n",
            "valid Loss: 4.07615 Acc: 7.585\n",
            "correct : 800 / 8000\n",
            "accuracy : 0.100\n",
            "\n",
            "Epoch 9/99\n",
            "----------\n",
            "train Loss: 0.32129 Acc: 89.042\n",
            "valid Loss: 3.87781 Acc: 7.784\n",
            "correct : 832 / 8000\n",
            "accuracy : 0.104\n",
            "\n",
            "Epoch 10/99\n",
            "----------\n",
            "train Loss: 0.25924 Acc: 90.839\n",
            "valid Loss: 4.37699 Acc: 7.585\n",
            "correct : 872 / 8000\n",
            "accuracy : 0.109\n",
            "\n",
            "Epoch 11/99\n",
            "----------\n",
            "train Loss: 0.29154 Acc: 89.929\n",
            "valid Loss: 3.20732 Acc: 20.559\n",
            "correct : 1709 / 8000\n",
            "accuracy : 0.214\n",
            "\n",
            "Epoch 12/99\n",
            "----------\n",
            "train Loss: 0.24675 Acc: 92.103\n",
            "valid Loss: 2.81552 Acc: 29.142\n",
            "correct : 2776 / 8000\n",
            "accuracy : 0.347\n",
            "\n",
            "Epoch 13/99\n",
            "----------\n",
            "train Loss: 0.23206 Acc: 92.147\n",
            "valid Loss: 3.44968 Acc: 32.535\n",
            "correct : 2803 / 8000\n",
            "accuracy : 0.350\n",
            "\n",
            "Epoch 14/99\n",
            "----------\n",
            "train Loss: 0.25278 Acc: 91.371\n",
            "valid Loss: 3.06802 Acc: 39.321\n",
            "correct : 3498 / 8000\n",
            "accuracy : 0.437\n",
            "\n",
            "Epoch 15/99\n",
            "----------\n",
            "train Loss: 0.17806 Acc: 94.343\n",
            "valid Loss: 2.97945 Acc: 42.515\n",
            "correct : 3513 / 8000\n",
            "accuracy : 0.439\n",
            "\n",
            "Epoch 16/99\n",
            "----------\n",
            "train Loss: 0.13049 Acc: 95.519\n",
            "valid Loss: 3.20675 Acc: 38.723\n",
            "correct : 3454 / 8000\n",
            "accuracy : 0.432\n",
            "\n",
            "Epoch 17/99\n",
            "----------\n",
            "train Loss: 0.09841 Acc: 97.072\n",
            "valid Loss: 2.95627 Acc: 43.513\n",
            "correct : 3633 / 8000\n",
            "accuracy : 0.454\n",
            "\n",
            "Epoch 18/99\n",
            "----------\n",
            "train Loss: 0.10990 Acc: 96.007\n",
            "valid Loss: 3.14496 Acc: 42.515\n",
            "correct : 3740 / 8000\n",
            "accuracy : 0.468\n",
            "\n",
            "Epoch 19/99\n",
            "----------\n",
            "train Loss: 0.15716 Acc: 94.854\n",
            "valid Loss: 3.31503 Acc: 42.914\n",
            "correct : 3643 / 8000\n",
            "accuracy : 0.455\n",
            "\n",
            "Epoch 20/99\n",
            "----------\n",
            "train Loss: 0.17201 Acc: 94.343\n",
            "valid Loss: 3.28063 Acc: 42.116\n",
            "correct : 3629 / 8000\n",
            "accuracy : 0.454\n",
            "\n",
            "Epoch 21/99\n",
            "----------\n",
            "train Loss: 0.13302 Acc: 95.963\n",
            "valid Loss: 3.34505 Acc: 43.713\n",
            "correct : 3761 / 8000\n",
            "accuracy : 0.470\n",
            "\n",
            "Epoch 22/99\n",
            "----------\n",
            "train Loss: 0.08960 Acc: 97.072\n",
            "valid Loss: 3.10724 Acc: 44.511\n",
            "correct : 3804 / 8000\n",
            "accuracy : 0.475\n",
            "\n",
            "Epoch 23/99\n",
            "----------\n",
            "train Loss: 0.12193 Acc: 96.140\n",
            "valid Loss: 3.15977 Acc: 43.912\n",
            "correct : 3727 / 8000\n",
            "accuracy : 0.466\n",
            "\n",
            "Epoch 24/99\n",
            "----------\n",
            "train Loss: 0.12173 Acc: 96.096\n",
            "valid Loss: 3.14690 Acc: 45.709\n",
            "correct : 3684 / 8000\n",
            "accuracy : 0.461\n",
            "\n",
            "Epoch 25/99\n",
            "----------\n",
            "train Loss: 0.11337 Acc: 96.229\n",
            "valid Loss: 3.21911 Acc: 46.307\n",
            "correct : 3734 / 8000\n",
            "accuracy : 0.467\n",
            "\n",
            "Epoch 26/99\n",
            "----------\n",
            "train Loss: 0.15452 Acc: 95.209\n",
            "valid Loss: 3.19244 Acc: 43.313\n",
            "correct : 3566 / 8000\n",
            "accuracy : 0.446\n",
            "\n",
            "Epoch 27/99\n",
            "----------\n",
            "train Loss: 0.15230 Acc: 95.120\n",
            "valid Loss: 3.29457 Acc: 42.116\n",
            "correct : 3634 / 8000\n",
            "accuracy : 0.454\n",
            "\n",
            "Epoch 28/99\n",
            "----------\n",
            "train Loss: 0.08678 Acc: 97.249\n",
            "valid Loss: 3.04377 Acc: 44.112\n",
            "correct : 3843 / 8000\n",
            "accuracy : 0.480\n",
            "\n",
            "Epoch 29/99\n",
            "----------\n",
            "train Loss: 0.06063 Acc: 98.004\n",
            "valid Loss: 3.10309 Acc: 42.715\n",
            "correct : 3720 / 8000\n",
            "accuracy : 0.465\n",
            "\n",
            "Epoch 30/99\n",
            "----------\n",
            "train Loss: 0.08318 Acc: 97.183\n",
            "valid Loss: 3.10602 Acc: 45.709\n",
            "correct : 3746 / 8000\n",
            "accuracy : 0.468\n",
            "\n",
            "Epoch 31/99\n",
            "----------\n",
            "train Loss: 0.10376 Acc: 96.695\n",
            "valid Loss: 3.21530 Acc: 45.908\n",
            "correct : 3728 / 8000\n",
            "accuracy : 0.466\n",
            "\n",
            "Epoch 32/99\n",
            "----------\n",
            "train Loss: 0.08313 Acc: 97.227\n",
            "valid Loss: 3.39232 Acc: 43.313\n",
            "correct : 3659 / 8000\n",
            "accuracy : 0.457\n",
            "\n",
            "Epoch 33/99\n",
            "----------\n",
            "train Loss: 0.09465 Acc: 96.739\n",
            "valid Loss: 3.42384 Acc: 44.311\n",
            "correct : 3722 / 8000\n",
            "accuracy : 0.465\n",
            "\n",
            "Epoch 34/99\n",
            "----------\n",
            "train Loss: 0.13801 Acc: 95.541\n",
            "valid Loss: 3.28348 Acc: 44.910\n",
            "correct : 3665 / 8000\n",
            "accuracy : 0.458\n",
            "\n",
            "Epoch 35/99\n",
            "----------\n",
            "train Loss: 0.07652 Acc: 97.715\n",
            "valid Loss: 3.50572 Acc: 42.116\n",
            "correct : 3736 / 8000\n",
            "accuracy : 0.467\n",
            "\n",
            "Epoch 36/99\n",
            "----------\n",
            "train Loss: 0.08196 Acc: 97.138\n",
            "valid Loss: 3.70886 Acc: 43.513\n",
            "correct : 3732 / 8000\n",
            "accuracy : 0.467\n",
            "\n",
            "Epoch 37/99\n",
            "----------\n",
            "train Loss: 0.09664 Acc: 97.005\n",
            "valid Loss: 3.25306 Acc: 42.116\n",
            "correct : 3755 / 8000\n",
            "accuracy : 0.469\n",
            "\n",
            "Epoch 38/99\n",
            "----------\n",
            "train Loss: 0.07569 Acc: 97.671\n",
            "valid Loss: 3.24666 Acc: 44.910\n",
            "correct : 3780 / 8000\n",
            "accuracy : 0.472\n",
            "\n",
            "Epoch 39/99\n",
            "----------\n",
            "train Loss: 0.07129 Acc: 97.693\n",
            "valid Loss: 3.43604 Acc: 44.711\n",
            "correct : 3847 / 8000\n",
            "accuracy : 0.481\n",
            "\n",
            "Epoch 40/99\n",
            "----------\n",
            "train Loss: 0.08774 Acc: 97.183\n",
            "valid Loss: 3.24878 Acc: 43.513\n",
            "correct : 3650 / 8000\n",
            "accuracy : 0.456\n",
            "\n",
            "Epoch 41/99\n",
            "----------\n",
            "train Loss: 0.07431 Acc: 97.582\n",
            "valid Loss: 3.30356 Acc: 44.112\n",
            "correct : 3699 / 8000\n",
            "accuracy : 0.462\n",
            "\n",
            "Epoch 42/99\n",
            "----------\n",
            "train Loss: 0.05241 Acc: 98.492\n",
            "valid Loss: 3.28862 Acc: 42.315\n",
            "correct : 3695 / 8000\n",
            "accuracy : 0.462\n",
            "\n",
            "Epoch 43/99\n",
            "----------\n",
            "train Loss: 0.07505 Acc: 97.538\n",
            "valid Loss: 3.36181 Acc: 46.507\n",
            "correct : 3856 / 8000\n",
            "accuracy : 0.482\n",
            "\n",
            "Epoch 44/99\n",
            "----------\n",
            "train Loss: 0.05180 Acc: 98.314\n",
            "valid Loss: 3.11234 Acc: 45.509\n",
            "correct : 3782 / 8000\n",
            "accuracy : 0.473\n",
            "\n",
            "Epoch 45/99\n",
            "----------\n",
            "train Loss: 0.07332 Acc: 97.604\n",
            "valid Loss: 3.58724 Acc: 42.116\n",
            "correct : 3627 / 8000\n",
            "accuracy : 0.453\n",
            "\n",
            "Epoch 46/99\n",
            "----------\n",
            "train Loss: 0.07915 Acc: 97.427\n",
            "valid Loss: 3.58057 Acc: 45.709\n",
            "correct : 3831 / 8000\n",
            "accuracy : 0.479\n",
            "\n",
            "Epoch 47/99\n",
            "----------\n",
            "train Loss: 0.06351 Acc: 97.782\n",
            "valid Loss: 3.60855 Acc: 44.910\n",
            "correct : 3761 / 8000\n",
            "accuracy : 0.470\n",
            "\n",
            "Epoch 48/99\n",
            "----------\n",
            "train Loss: 0.05786 Acc: 98.114\n",
            "valid Loss: 3.80962 Acc: 46.307\n",
            "correct : 3938 / 8000\n",
            "accuracy : 0.492\n",
            "\n",
            "Epoch 49/99\n",
            "----------\n",
            "train Loss: 0.07469 Acc: 97.826\n",
            "valid Loss: 3.51360 Acc: 43.313\n",
            "correct : 3855 / 8000\n",
            "accuracy : 0.482\n",
            "\n",
            "Epoch 50/99\n",
            "----------\n",
            "train Loss: 0.04330 Acc: 98.625\n",
            "valid Loss: 3.50322 Acc: 42.914\n",
            "correct : 3867 / 8000\n",
            "accuracy : 0.483\n",
            "\n",
            "Epoch 51/99\n",
            "----------\n",
            "train Loss: 0.03228 Acc: 99.113\n",
            "valid Loss: 3.35721 Acc: 46.108\n",
            "correct : 3864 / 8000\n",
            "accuracy : 0.483\n",
            "\n",
            "Epoch 52/99\n",
            "----------\n",
            "train Loss: 0.05889 Acc: 98.248\n",
            "valid Loss: 3.42359 Acc: 46.307\n",
            "correct : 3830 / 8000\n",
            "accuracy : 0.479\n",
            "\n",
            "Epoch 53/99\n",
            "----------\n",
            "train Loss: 0.04983 Acc: 98.381\n",
            "valid Loss: 3.54465 Acc: 43.912\n",
            "correct : 3726 / 8000\n",
            "accuracy : 0.466\n",
            "\n",
            "Epoch 54/99\n",
            "----------\n",
            "train Loss: 0.07088 Acc: 97.959\n",
            "valid Loss: 3.48340 Acc: 43.513\n",
            "correct : 3856 / 8000\n",
            "accuracy : 0.482\n",
            "\n",
            "Epoch 55/99\n",
            "----------\n",
            "train Loss: 0.12147 Acc: 96.517\n",
            "valid Loss: 3.60890 Acc: 45.309\n",
            "correct : 3645 / 8000\n",
            "accuracy : 0.456\n",
            "\n",
            "Epoch 56/99\n",
            "----------\n",
            "train Loss: 0.10207 Acc: 97.005\n",
            "valid Loss: 3.43738 Acc: 44.311\n",
            "correct : 3686 / 8000\n",
            "accuracy : 0.461\n",
            "\n",
            "Epoch 57/99\n",
            "----------\n",
            "train Loss: 0.06762 Acc: 98.004\n",
            "valid Loss: 3.52036 Acc: 45.309\n",
            "correct : 3887 / 8000\n",
            "accuracy : 0.486\n",
            "\n",
            "Epoch 58/99\n",
            "----------\n",
            "train Loss: 0.03917 Acc: 98.891\n",
            "valid Loss: 3.49323 Acc: 44.311\n",
            "correct : 3837 / 8000\n",
            "accuracy : 0.480\n",
            "\n",
            "Epoch 59/99\n",
            "----------\n",
            "train Loss: 0.05826 Acc: 98.292\n",
            "valid Loss: 3.48612 Acc: 44.910\n",
            "correct : 3778 / 8000\n",
            "accuracy : 0.472\n",
            "\n",
            "Epoch 60/99\n",
            "----------\n",
            "train Loss: 0.06871 Acc: 97.715\n",
            "valid Loss: 3.39304 Acc: 44.910\n",
            "correct : 3856 / 8000\n",
            "accuracy : 0.482\n",
            "\n",
            "Epoch 61/99\n",
            "----------\n",
            "train Loss: 0.03901 Acc: 98.957\n",
            "valid Loss: 3.29566 Acc: 45.908\n",
            "correct : 3913 / 8000\n",
            "accuracy : 0.489\n",
            "\n",
            "Epoch 62/99\n",
            "----------\n",
            "train Loss: 0.02460 Acc: 99.246\n",
            "valid Loss: 3.22056 Acc: 46.108\n",
            "correct : 3963 / 8000\n",
            "accuracy : 0.495\n",
            "\n",
            "Epoch 63/99\n",
            "----------\n",
            "train Loss: 0.02637 Acc: 99.423\n",
            "valid Loss: 3.18922 Acc: 46.906\n",
            "correct : 3949 / 8000\n",
            "accuracy : 0.494\n",
            "\n",
            "Epoch 64/99\n",
            "----------\n",
            "train Loss: 0.01869 Acc: 99.490\n",
            "valid Loss: 3.14720 Acc: 46.307\n",
            "correct : 3906 / 8000\n",
            "accuracy : 0.488\n",
            "\n",
            "Epoch 65/99\n",
            "----------\n",
            "train Loss: 0.02111 Acc: 99.357\n",
            "valid Loss: 3.36976 Acc: 47.505\n",
            "correct : 3897 / 8000\n",
            "accuracy : 0.487\n",
            "\n",
            "Epoch 66/99\n",
            "----------\n",
            "train Loss: 0.01688 Acc: 99.445\n",
            "valid Loss: 3.49170 Acc: 46.906\n",
            "correct : 3921 / 8000\n",
            "accuracy : 0.490\n",
            "\n",
            "Epoch 67/99\n",
            "----------\n",
            "train Loss: 0.02131 Acc: 99.357\n",
            "valid Loss: 3.57564 Acc: 45.110\n",
            "correct : 3782 / 8000\n",
            "accuracy : 0.473\n",
            "\n",
            "Epoch 68/99\n",
            "----------\n",
            "train Loss: 0.03399 Acc: 98.935\n",
            "valid Loss: 3.31067 Acc: 44.711\n",
            "correct : 3810 / 8000\n",
            "accuracy : 0.476\n",
            "\n",
            "Epoch 69/99\n",
            "----------\n",
            "train Loss: 0.08047 Acc: 97.760\n",
            "valid Loss: 3.55014 Acc: 41.517\n",
            "correct : 3728 / 8000\n",
            "accuracy : 0.466\n",
            "\n",
            "Epoch 70/99\n",
            "----------\n",
            "train Loss: 0.06074 Acc: 98.181\n",
            "valid Loss: 3.34291 Acc: 45.110\n",
            "correct : 3746 / 8000\n",
            "accuracy : 0.468\n",
            "\n",
            "Epoch 71/99\n",
            "----------\n",
            "train Loss: 0.07114 Acc: 97.626\n",
            "valid Loss: 3.34376 Acc: 44.511\n",
            "correct : 3693 / 8000\n",
            "accuracy : 0.462\n",
            "\n",
            "Epoch 72/99\n",
            "----------\n",
            "train Loss: 0.09493 Acc: 96.939\n",
            "valid Loss: 3.76924 Acc: 42.116\n",
            "correct : 3562 / 8000\n",
            "accuracy : 0.445\n",
            "\n",
            "Epoch 73/99\n",
            "----------\n",
            "train Loss: 0.06682 Acc: 97.893\n",
            "valid Loss: 3.45836 Acc: 45.908\n",
            "correct : 3824 / 8000\n",
            "accuracy : 0.478\n",
            "\n",
            "Epoch 74/99\n",
            "----------\n",
            "train Loss: 0.03358 Acc: 99.046\n",
            "valid Loss: 3.18173 Acc: 47.305\n",
            "correct : 3889 / 8000\n",
            "accuracy : 0.486\n",
            "\n",
            "Epoch 75/99\n",
            "----------\n",
            "train Loss: 0.04335 Acc: 98.558\n",
            "valid Loss: 3.42069 Acc: 43.912\n",
            "correct : 3820 / 8000\n",
            "accuracy : 0.477\n",
            "\n",
            "Epoch 76/99\n",
            "----------\n",
            "train Loss: 0.03302 Acc: 99.068\n",
            "valid Loss: 3.19477 Acc: 45.908\n",
            "correct : 3922 / 8000\n",
            "accuracy : 0.490\n",
            "\n",
            "Epoch 77/99\n",
            "----------\n",
            "train Loss: 0.03217 Acc: 99.157\n",
            "valid Loss: 3.17041 Acc: 46.108\n",
            "correct : 3910 / 8000\n",
            "accuracy : 0.489\n",
            "\n",
            "Epoch 78/99\n",
            "----------\n",
            "train Loss: 0.01881 Acc: 99.379\n",
            "valid Loss: 3.17046 Acc: 45.908\n",
            "correct : 3886 / 8000\n",
            "accuracy : 0.486\n",
            "\n",
            "Epoch 79/99\n",
            "----------\n",
            "train Loss: 0.02055 Acc: 99.268\n",
            "valid Loss: 3.09837 Acc: 47.505\n",
            "correct : 3870 / 8000\n",
            "accuracy : 0.484\n",
            "\n",
            "Epoch 80/99\n",
            "----------\n",
            "train Loss: 0.01949 Acc: 99.445\n",
            "valid Loss: 3.25567 Acc: 47.705\n",
            "correct : 3934 / 8000\n",
            "accuracy : 0.492\n",
            "\n",
            "Epoch 81/99\n",
            "----------\n",
            "train Loss: 0.02522 Acc: 99.091\n",
            "valid Loss: 3.21306 Acc: 48.503\n",
            "correct : 3972 / 8000\n",
            "accuracy : 0.496\n",
            "\n",
            "Epoch 82/99\n",
            "----------\n",
            "train Loss: 0.02968 Acc: 99.024\n",
            "valid Loss: 3.50063 Acc: 46.507\n",
            "correct : 3798 / 8000\n",
            "accuracy : 0.475\n",
            "\n",
            "Epoch 83/99\n",
            "----------\n",
            "train Loss: 0.12013 Acc: 96.473\n",
            "valid Loss: 3.55827 Acc: 47.305\n",
            "correct : 3702 / 8000\n",
            "accuracy : 0.463\n",
            "\n",
            "Epoch 84/99\n",
            "----------\n",
            "train Loss: 0.10486 Acc: 96.451\n",
            "valid Loss: 3.57813 Acc: 42.914\n",
            "correct : 3824 / 8000\n",
            "accuracy : 0.478\n",
            "\n",
            "Epoch 85/99\n",
            "----------\n",
            "train Loss: 0.06575 Acc: 97.848\n",
            "valid Loss: 3.64648 Acc: 46.108\n",
            "correct : 3896 / 8000\n",
            "accuracy : 0.487\n",
            "\n",
            "Epoch 86/99\n",
            "----------\n",
            "train Loss: 0.05394 Acc: 97.959\n",
            "valid Loss: 3.58086 Acc: 48.104\n",
            "correct : 3907 / 8000\n",
            "accuracy : 0.488\n",
            "\n",
            "Epoch 87/99\n",
            "----------\n",
            "train Loss: 0.07321 Acc: 97.671\n",
            "valid Loss: 3.62280 Acc: 43.313\n",
            "correct : 3649 / 8000\n",
            "accuracy : 0.456\n",
            "\n",
            "Epoch 88/99\n",
            "----------\n",
            "train Loss: 0.05185 Acc: 98.225\n",
            "valid Loss: 3.39529 Acc: 48.104\n",
            "correct : 3806 / 8000\n",
            "accuracy : 0.476\n",
            "\n",
            "Epoch 89/99\n",
            "----------\n",
            "train Loss: 0.06023 Acc: 98.314\n",
            "valid Loss: 3.30601 Acc: 45.309\n",
            "correct : 3906 / 8000\n",
            "accuracy : 0.488\n",
            "\n",
            "Epoch 90/99\n",
            "----------\n",
            "train Loss: 0.05175 Acc: 98.492\n",
            "valid Loss: 3.31151 Acc: 49.301\n",
            "correct : 3979 / 8000\n",
            "accuracy : 0.497\n",
            "\n",
            "Epoch 91/99\n",
            "----------\n",
            "train Loss: 0.03340 Acc: 98.802\n",
            "valid Loss: 3.24270 Acc: 47.305\n",
            "correct : 3992 / 8000\n",
            "accuracy : 0.499\n",
            "\n",
            "Epoch 92/99\n",
            "----------\n",
            "train Loss: 0.02491 Acc: 99.091\n",
            "valid Loss: 3.23321 Acc: 46.707\n",
            "correct : 3957 / 8000\n",
            "accuracy : 0.495\n",
            "\n",
            "Epoch 93/99\n",
            "----------\n",
            "train Loss: 0.04637 Acc: 98.492\n",
            "valid Loss: 3.63922 Acc: 43.713\n",
            "correct : 3853 / 8000\n",
            "accuracy : 0.482\n",
            "\n",
            "Epoch 94/99\n",
            "----------\n",
            "train Loss: 0.02709 Acc: 99.224\n",
            "valid Loss: 3.40987 Acc: 48.303\n",
            "correct : 3989 / 8000\n",
            "accuracy : 0.499\n",
            "\n",
            "Epoch 95/99\n",
            "----------\n",
            "train Loss: 0.04973 Acc: 98.514\n",
            "valid Loss: 3.39910 Acc: 46.108\n",
            "correct : 3859 / 8000\n",
            "accuracy : 0.482\n",
            "\n",
            "Epoch 96/99\n",
            "----------\n",
            "train Loss: 0.03482 Acc: 98.957\n",
            "valid Loss: 3.34422 Acc: 48.503\n",
            "correct : 3878 / 8000\n",
            "accuracy : 0.485\n",
            "\n",
            "Epoch 97/99\n",
            "----------\n",
            "train Loss: 0.04733 Acc: 98.381\n",
            "valid Loss: 3.62634 Acc: 47.904\n",
            "correct : 4017 / 8000\n",
            "accuracy : 0.502\n",
            "\n",
            "Epoch 98/99\n",
            "----------\n",
            "train Loss: 0.05223 Acc: 98.469\n",
            "valid Loss: 3.40331 Acc: 45.709\n",
            "correct : 3997 / 8000\n",
            "accuracy : 0.500\n",
            "\n",
            "Epoch 99/99\n",
            "----------\n",
            "train Loss: 0.05478 Acc: 98.358\n",
            "valid Loss: 3.51677 Acc: 45.309\n",
            "correct : 3982 / 8000\n",
            "accuracy : 0.498\n",
            "\n",
            "Training complete in 32m 4s\n",
            "Best valid Acc: 0 - 2.31129\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOJLxMYCScvN",
        "outputId": "6cefd1ea-0970-4ce7-a9f1-2edde267eb83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Number of parameters: {pytorch_total_params}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of parameters: 4020358\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLZDvFetYKA-",
        "outputId": "6827b122-4152-4d6d-d74e-5eafad77186f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "## 결과 그래프 그리기\n",
        "print('best model : %d - %1.f / %.1f'%(best_idx, valid_acc[best_idx], valid_loss[best_idx]))\n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "ax1.plot(train_acc[:100], 'b-')\n",
        "ax1.plot(valid_acc[:100], 'r-')\n",
        "# plt.plot(best_idx, valid_acc[best_idx], 'ro')\n",
        "ax1.set_xlabel('epoch')\n",
        "# Make the y-axis label, ticks and tick labels match the line color.\n",
        "ax1.set_ylabel('acc', color='k')\n",
        "ax1.tick_params('y', colors='k')\n",
        "plt.title(\"B0_without_augmentation\")\n",
        "# ax2 = ax1.twinx()\n",
        "# ax2.plot(train_loss, 'g-')\n",
        "# ax2.plot(valid_loss, 'k-')\n",
        "# plt.plot(best_idx, valid_loss[best_idx], 'ro')\n",
        "# ax2.set_ylabel('loss', color='k')\n",
        "# ax2.tick_params('y', colors='k')\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best model : 0 - 8 / 2.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GV64BPmRc6Fa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}